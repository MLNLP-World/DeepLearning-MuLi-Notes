## 18-预测房价竞赛总结

### 本节目录

- [1.方法总结](#1方法总结)
- [2.分析](#2分析)
- [3.关于automl](#3关于automl)
  * [3.1 课程内容](#31-课程内容)
  * [3.2 补充内容](#32-补充内容)
    + [AutoGluon](#autogluon)
- [4.总结](#4总结)
- [5.预测房价竞赛总结 Q&A](#5预测房价竞赛总结-qa)

### 1.方法总结

> 下面提供了排行榜前几使用的方法介绍链接

- 第二和第七：autogluon

  https://www.bilibili.com/video/BV1rh411m7Hb/

- 第三：h2o

  https://www.kaggle.com/wuwawa/automl-using-h2o

- 第四：随机森林

  https://www.kaggle.com/jackzh/the-4th-place-approach-random-forest

### 2.分析

- 已知的排名靠前的4个成绩均使用了集成学习

- 目前不知道是否有使用书中的mlp取得好成绩

  > 通过调参数，是能够取得很好的结果的

   对于mlp来说，特征预处理和超参数的调节是取得好成绩的基础

- 数据的难点

  - 数值较大

    > 梯度相对较大，容易发生梯度爆炸

    一个解决方案是可以对数据取对数，再进行标准化

  - 有文本特征（地址，介绍）

    > 这些文字可能含有较多的噪声，对模型产生影响

    解决办法日后会讲解，比如第二名用的transformer

  - 训练数据是前6个月，公榜是后3个月，私榜是再往后3个月

    > 利用历史的数据进行训练，在实践中自然会有不同的影响（可能过拟合）
    >
    > 因此公榜与私榜的排名有一定差异

               这个问题称为Covariate Shift，没有特别好的解决方案  ，可以让模型尽可能稳定，不去仔细调参

### 3.关于automl

#### 3.1 课程内容

> 这一部分李沐老师要表达的主要是我们应该深入去了解本后的原理，不要因为有"自动化"深度学习而产生一种依赖心理或者变得没有深究深度学习的动力，学习deep learning仍然是有意义的

- 数据科学家80%时间在处理数据，20%调模型

  > 处理数据是automl不能做的，automl的作用主要在调模型这块，数据科学家仍然能大展身手

- Automl现在能处理一些基础的情况

  > 目前节省10%时间，未来节省20%时间

- 为什么还要学习深度学习

  正如买菜只需要用到四则运算甚至不用，我们仍然需要学习三角函数去进行更深入的科学研究等其他事情。当人人都会用Automl的时候，我们仍然需要懂得一些底层的原理，毕竟Automl也是有局限性的，需要我们不断改进，或者想出其他算法。另一方面，我们也要肯定Automl带来的便利。

#### 3.2 补充内容

##### AutoGluon

> 与大部分automl框架是基于超参数搜索技术的不同，Autogluon会利用多个机器学习包来训练模型

- 房价预测竞赛中模型的改动

  > 1.对于数据中数值比较大且数据变化大的数值取log,CPU上训练2个小时，最终排第七
  >
  > 2.房子描述里包含大量文本，使用mutimodal选项来用transformer提取特征，并做多模型融合,用GPU才跑得动，排名第二

- AutoGluon背后的技术

  > 1.stacking
  >
  > 2.k-则交叉bagging
  >
  > 3.多层stacking

- 总结

  > 1.autogluon在合理的计算开销下得到还不错的模型
  >
  > 2.虽然autogluon可以做自动特征抽取，但是当加入一些人工数据处理也是不错的方法
  >
  > 3.对于比较大的数据集计算开销仍然是瓶颈，需要使用GPU甚至多台机器做分布式训练，这仍是AutoML未来的研究方向
  >
  > 4.具体讲解可参考：https://www.bilibili.com/video/BV1F84y1F7Ps/?spm_id_from=333.788.recommend_more_video.1

### 4.总结

这节课本身就是一次对预测房价竞赛的总结，主要介绍了排名的分布情况以及一些队伍使用的方法。

### 5.预测房价竞赛总结 Q&A

**Q1: 统计学专业本科生未来从事人工智能如何规划**

> 注重动手能力的培养

**Q2: 避免overfit是调参好还是不调参好？老师有何经验分享？**

> 调参是需要的，首先最好有一个比较好的验证集；当你找到一个在验证集效果比较好的超参数值的时候，最好在这一值上调或下调一点看看是否敏感，如果比较敏感说明这点可能只是在这点凑巧效果好罢了，泛化性就不好；当然在实践中调参并没有像在竞赛中那么重要

**Q3: 老师说的80%时间处理数据是指的找数据、清理数据这些？数据搭建pipeline不就好了， ？为什么改进模型等等不占主要时间？**

> 处理数据并不是搭建pipeline就好了，你需要决定从哪里获取数据、怎样获取数据、如何处理噪音（清理数据）......这些都是很费时间的

**Q4: AutoML与ML有严格的特征区别吗**

> AutoML可以看作是ML中的一类算法

**Q5: 用mlp做竞赛时发现层数深的时候预测出来的房价全是一样的，层数浅一点还不会出现这个问题，为什么？**

> 应该是梯度爆炸，或者梯度消失，也就是数值稳定性出现问题

**Q6：MLP有值得精细调参的价值吗？**

> 有。

